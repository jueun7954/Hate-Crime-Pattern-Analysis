---
title: "Final Project"
author: "Jueun Park"
date: "2024-10-23"
output: 
  html_document:
    code_folding: hide
---


```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(openxlsx)
library(readxl)
library(plyr) # join all
library(stringr) #string separate 
library(ggthemes)
library(stringr)
library(broom)
library(glmnet)
library(plm) #panel data regression
library(car) #VIF
library(forecast) #prediction
```

```{r message=FALSE, warning=FALSE}
#Cleaning hate crime report data
#Read state abbreviation data

state_abbrev <- read.csv("state_abbrev.csv")
state_abbrev <- state_abbrev %>%
  dplyr::rename(state = State,
                state_abbrev = Abbreviation)

hate <- read.csv("hate_crime.csv")

hate_data <- hate %>%
  dplyr::rename(year = data_year,state = state_name) %>%
  left_join(state_abbrev, by=("state"))


# Categorize sub bias type into bigger category
hate_data <- hate_data %>%
  mutate(
    bias_desc = str_to_lower(bias_desc),
    bias_category = case_when(
      str_detect(bias_desc, "black|white|asian|hispanic|arab|american indian") ~ "Race/Ethnicity",
      str_detect(bias_desc, "jewish|muslim|catholic|protestant|hindu|sikh") ~ "Religion",
      str_detect(bias_desc, "gay|lesbian|transgender|lgbtq|bisexual") ~ "Sexual Orientation/Gender Identity",
      str_detect(bias_desc, "physical disability|mental disability") ~ "Disability",
      str_detect(bias_desc, "heterosexual|gender non-conforming|male|female") ~ "Other Social Groups",
      TRUE ~ "Intersectional Bias"
    )
  )
```

```{r message=FALSE, warning=FALSE}
#Cleaning GDP data

#Read gdp dataset
gdp <- read.csv("GDP_state.csv", skip=3)

#Rename columns
gdp_data <- dplyr::rename(gdp,
                   state = GeoName,
                   "2016" = X2016,
                   "2017" = X2017,
                   "2018" = X2018,
                   "2019" = X2019,
                  "2020" = X2020,
                  "2021" = X2021,
                  "2022" = X2022,
                  "2023" = X2023)

#Remove column that is not needed
gdp_data = subset(gdp_data, select = -c(GeoFips)) 

#Final Tidy dataset for GDP
GDP_state_trans <- pivot_longer(
  gdp_data,
  cols = -state, 
  names_to = "year", 
  values_to = "gdp"
)
```

```{r message=FALSE, warning=FALSE}
#Cleaning Political data

political <- read.xlsx("political_state.xlsx", sheet = "16. Appendix 1A")

#Election result - 2020
result_2020 <- political %>% select("Appendix.A:.1996-2020.Presidential.General.Election", X2, X3)
result_2020 <- result_2020[-(1:5),]

result_2020 <- dplyr::rename(result_2020,
                      state = "Appendix.A:.1996-2020.Presidential.General.Election",
                      Democratic = X2,
                      Republican = X3)

result_2020 <- result_2020 %>%
  mutate(
    Democratic = as.numeric(Democratic),
    Republican = as.numeric(Republican),
    "2020" = ifelse(Democratic > Republican, "Democratic", "Republican")
  )


#Election result - 2016
result_2016 <- political %>% select("Appendix.A:.1996-2020.Presidential.General.Election", X4, X5)
result_2016 <- result_2016[-(1:5),]

result_2016 <- dplyr::rename(result_2016,
                      state = "Appendix.A:.1996-2020.Presidential.General.Election",
                      Democratic = X4,
                      Republican = X5) %>%
  mutate(
    Democratic = as.numeric(Democratic),
    Republican = as.numeric(Republican),
    "2016" = ifelse(Democratic > Republican, "Democratic", "Republican")
  )

# Total Election result 2016-2020
# Final Tidy dataset for political leaning
political_leaning_trans <- left_join(result_2020, result_2016, by=("state")) %>%
  select(state, "2020", "2016") %>%
  pivot_longer(
  cols = -state, 
  names_to = "year", 
  values_to = "political"
) %>%
  filter(row_number() <= n()-6)
```

```{r message=FALSE, warning=FALSE}
#Cleaning Population density data


# Read files for this variable
land_area <- read.csv("state_landArea.csv")
state_pop <- read_excel("population_state.xls", sheet = "Annual")



#Extract only year
state_pop$DATE <- gsub("-01-01","", as.character(state_pop$DATE))

#Tidy data
state_pop_trans <- pivot_longer(
  state_pop,
  cols = -DATE, 
  names_to = "state_abbrev", 
  values_to = "population"
)

#Extract only state abbreviation
state_pop_trans$state_abbrev <- gsub("POP","", as.character(state_pop_trans$state_abbrev))


#Join necessary dataset
state_pop_trans <- left_join(state_pop_trans, state_abbrev, by=("state_abbrev"))
state_pop_trans <- left_join(state_pop_trans, land_area, by=("state"))

#Final dataset for population density
pop_density <- state_pop_trans %>%
  mutate(density = round((population*1000)/LandArea), digits = 2) %>%
  select(state, state_abbrev, DATE, density) %>%
  dplyr::rename(year = DATE)
```


```{r message=FALSE, warning=FALSE}
#Cleaning Unemployment data

#read uemployment data by state
unemp_state <- read_xlsx("unemployment_state.xlsx", skip = 6)

#Final Tidy unemployment data
unemp_state <- unemp_state %>%
  select("...2","Labor force...3", "rate") %>%
  dplyr::rename(state ="...2",
         year = "Labor force...3",
         unemp_rate = "rate") %>%
  filter(year > 2015) %>%
  group_by(state, year) %>%
  dplyr::summarize(avg.emp = round(mean(unemp_rate),2), .groups = "keep")
  
```

```{r message=FALSE, warning=FALSE}
#Cleaning gender distribution data

#Reading all the dataset for gender distribution(2016-2023)
gender_2023 <- read.csv("sex_2023.csv", skip = 2) %>%
  select(Location, Male, Female) %>%
  dplyr::rename(state = Location,
         "Male 2023" = Male,
         "Female 2023" = Female)

gender_2022 <- read.csv("sex_2022.csv", skip = 2) %>%
  select(Location, Male, Female) %>%
  dplyr::rename(state = Location,
         "Male 2022" = Male,
         "Female 2022" = Female)

gender_2021 <- read.csv("sex_2021.csv", skip = 2) %>%
  select(Location, Male, Female) %>%
  dplyr::rename(state = Location,
         "Male 2021" = Male,
         "Female 2021" = Female)

gender_2019 <- read.csv("sex_2019.csv", skip = 2) %>%
  select(Location, Male, Female) %>%
  dplyr::rename(state = Location,
         "Male 2019" = Male,
         "Female 2019" = Female)

gender_2018 <- read.csv("sex_2018.csv", skip = 2) %>%
  select(Location, Male, Female) %>%
  dplyr::rename(state = Location,
         "Male 2018" = Male,
         "Female 2018" = Female)

gender_2017 <- read.csv("sex_2017.csv", skip = 2) %>%
  select(Location, Male, Female) %>%
  dplyr::rename(state = Location,
         "Male 2017" = Male,
         "Female 2017" = Female)

gender_2016 <- read.csv("sex_2016.csv", skip = 2) %>%
  select(Location, Male, Female) %>%
  dplyr::rename(state = Location,
         "Male 2016" = Male,
         "Female 2016" = Female)


#Join all the dataset
gender_dist <- join_all(list(gender_2016, gender_2017, gender_2018, gender_2019, gender_2021, gender_2022, gender_2023), by=("state"), type = "left")


#Final tidy gender distribution data
gender_dist_trans <- pivot_longer(
  gender_dist,
  cols = -state, 
  names_to = "gender", 
  values_to = "gender_dist"
)

gender_dist_trans[c('gender', 'year')] <- str_split_fixed(gender_dist_trans$gender, ' ', 2)
```

```{r message=FALSE, warning=FALSE}
#Cleaning race distribution data

#Reading all the dataset for race distribution(2016-2023)
race_2023 <- read.csv("race_2023.csv", skip = 2) %>%
  select(Location, White, Black, Hispanic, Asian) %>%
  dplyr::rename(state = Location,
         "White 2023" = White,
         "Black 2023" = Black,
         "Hispanic 2023" = Hispanic,
         "Asian 2023" = Asian)

race_2022 <- read.csv("race_2022.csv", skip = 2) %>%
  select(Location, White, Black, Hispanic, Asian) %>%
  dplyr::rename(state = Location,
         "White 2022" = White,
         "Black 2022" = Black,
         "Hispanic 2022" = Hispanic,
         "Asian 2022" = Asian)

race_2021 <- read.csv("race_2021.csv", skip = 2) %>%
  select(Location, White, Black, Hispanic, Asian) %>%
  dplyr::rename(state = Location,
         "White 2021" = White,
         "Black 2021" = Black,
         "Hispanic 2021" = Hispanic,
         "Asian 2021" = Asian)

race_2019 <- read.csv("race_2019.csv", skip = 2) %>%
  select(Location, White, Black, Hispanic, Asian) %>%
  dplyr::rename(state = Location,
         "White 2019" = White,
         "Black 2019" = Black,
         "Hispanic 2019" = Hispanic,
         "Asian 2019" = Asian)

race_2018 <- read.csv("race_2018.csv", skip = 2) %>%
  select(Location, White, Black, Hispanic, Asian) %>%
  dplyr::rename(state = Location,
         "White 2018" = White,
         "Black 2018" = Black,
         "Hispanic 2018" = Hispanic,
         "Asian 2018" = Asian)

race_2017 <- read.csv("race_2017.csv", skip = 2) %>%
  select(Location, White, Black, Hispanic, Asian) %>%
  dplyr::rename(state = Location,
         "White 2017" = White,
         "Black 2017" = Black,
         "Hispanic 2017" = Hispanic,
         "Asian 2017" = Asian)

race_2016 <- read.csv("race_2016.csv", skip = 2) %>%
  select(Location, White, Black, Hispanic, Asian) %>%
  dplyr::rename(state = Location,
         "White 2016" = White,
         "Black 2016" = Black,
         "Hispanic 2016" = Hispanic,
         "Asian 2016" = Asian)
  
race_2016$"Black 2016" <-gsub("<","0.",as.numeric(race_2016$"Black 2016"))
race_2017$"Black 2017" <-gsub("<","0.",as.numeric(race_2017$"Black 2017"))
race_2018$"Black 2018" <-gsub("<","0.",as.numeric(race_2018$"Black 2018"))


#Join all the dataset
race_dist <- join_all(list(race_2016, race_2017, race_2018, race_2019, race_2021, race_2022, race_2023), by=("state"), type = "left")

# Clean data
race_dist <- race_dist[-(54:65),]
race_dist[race_dist == "N/A"] <- NA

race_dist$"Black 2016" <- as.numeric(as.character(race_dist$"Black 2016"))
race_dist$"Asian 2016" <- as.numeric(as.character(race_dist$"Asian 2016"))
race_dist$"Black 2017" <- as.numeric(as.character(race_dist$"Black 2017"))
race_dist$"Asian 2017" <- as.numeric(as.character(race_dist$"Asian 2017"))
race_dist$"Black 2018" <- as.numeric(as.character(race_dist$"Black 2018"))
race_dist$"Asian 2018" <- as.numeric(as.character(race_dist$"Black 2018"))
race_dist$"Black 2019" <- as.numeric(as.character(race_dist$"Black 2019"))
race_dist$"Asian 2019" <- as.numeric(as.character(race_dist$"Black 2019"))
race_dist$"Asian 2021" <- as.numeric(as.character(race_dist$"Black 2021"))
race_dist$"Asian 2023" <- as.numeric(as.character(race_dist$"Black 2023"))

#Final tidy gender distribution data
race_dist_trans <- race_dist %>%
  pivot_longer(
  cols = -state, 
  names_to = "race", 
  values_to = "race_dist"
)

race_dist_trans[c('race', 'year')] <- str_split_fixed(race_dist_trans$race, ' ', 2)


```


```{r message=FALSE, warning=FALSE}
#Cleaning age distribution data

#Reading all the dataset for age distribution(2016-2023)
age_2023 <- read.csv("age_2023.csv", skip = 2) %>%
  select(Location, Children.0.18, Adults.19.25, Adults.26.34,Adults.35.54, Adults.55.64,X65.) %>%
  dplyr::rename(state = Location,
               "0-18 2023" = Children.0.18,
               "19-25 2023" = Adults.19.25,
               "26-34 2023" = Adults.26.34,
                "35-54 2023" = Adults.35.54,
                "55-64 2023" = Adults.55.64,
                "65+ 2023" = X65.)

age_2022 <- read.csv("age_2022.csv", skip = 2) %>%
  select(Location, Children.0.18, Adults.19.25, Adults.26.34,Adults.35.54, Adults.55.64,X65.) %>%
  dplyr::rename(state = Location,
               "0-18 2022" = Children.0.18,
               "19-25 2022" = Adults.19.25,
               "26-34 2022" = Adults.26.34,
                "35-54 2022" = Adults.35.54,
                "55-64 2022" = Adults.55.64,
                "65+ 2022" = X65.)

age_2021 <- read.csv("age_2021.csv", skip = 2) %>%
  select(Location, Children.0.18, Adults.19.25, Adults.26.34,Adults.35.54, Adults.55.64,X65.) %>%
  dplyr::rename(state = Location,
               "0-18 2021" = Children.0.18,
               "19-25 2021" = Adults.19.25,
               "26-34 2021" = Adults.26.34,
                "35-54 2021" = Adults.35.54,
                "55-64 2021" = Adults.55.64,
                "65+ 2021" = X65.)

age_2019 <- read.csv("age_2019.csv", skip = 2) %>%
  select(Location, Children.0.18, Adults.19.25, Adults.26.34,Adults.35.54, Adults.55.64,X65.) %>%
  dplyr::rename(state = Location,
               "0-18 2019" = Children.0.18,
               "19-25 2019" = Adults.19.25,
               "26-34 2019" = Adults.26.34,
                "35-54 2019" = Adults.35.54,
                "55-64 2019" = Adults.55.64,
                "65+ 2019" = X65.)

age_2018 <- read.csv("age_2018.csv", skip = 2) %>%
  select(Location, Children.0.18, Adults.19.25, Adults.26.34,Adults.35.54, Adults.55.64,X65.) %>%
  dplyr::rename(state = Location,
               "0-18 2018" = Children.0.18,
               "19-25 2018" = Adults.19.25,
               "26-34 2018" = Adults.26.34,
                "35-54 2018" = Adults.35.54,
                "55-64 2018" = Adults.55.64,
                "65+ 2018" = X65.)

age_2017 <- read.csv("age_2017.csv", skip = 2) %>%
  select(Location, Children.0.18, Adults.19.25, Adults.26.34,Adults.35.54, Adults.55.64,X65.) %>%
  dplyr::rename(state = Location,
               "0-18 2017" = Children.0.18,
               "19-25 2017" = Adults.19.25,
               "26-34 2017" = Adults.26.34,
                "35-54 2017" = Adults.35.54,
                "55-64 2017" = Adults.55.64,
                "65+ 2017" = X65.)

age_2016 <- read.csv("age_2016.csv", skip = 2) %>%
  select(Location, Children.0.18, Adults.19.25, Adults.26.34,Adults.35.54, Adults.55.64,X65.) %>%
  dplyr::rename(state = Location,
               "0-18 2016" = Children.0.18,
               "19-25 2016" = Adults.19.25,
               "26-34 2016" = Adults.26.34,
                "35-54 2016" = Adults.35.54,
                "55-64 2016" = Adults.55.64,
                "65+ 2016" = X65.)

#Join all the dataset
age_dist <- join_all(list(age_2016, age_2017, age_2018, age_2019, age_2021, age_2022, age_2023), by=("state"), type = "left")    


#Final tidy age distribution data
age_dist_trans <- age_dist %>%
  pivot_longer(
  cols = -state, 
  names_to = "age", 
  values_to = "age_dist"
)


age_dist_trans[c('age', 'year')] <- str_split_fixed(age_dist_trans$age, ' ', 2)   
```


---

# Analysis
```{r message=FALSE, warning=FALSE}
#Exploratory Analysis: Changes in Hate Crime Over Time 

# Summarize total hate crimes by year
hate_crime_trend <- hate_data %>%
  group_by(year) %>%
  dplyr::summarize(total_hate_crimes = n(), .groups = "keep") %>%
  mutate(event = case_when(
    year == 2001 ~ "9/11",
    year == 2008 ~ "Financial Crisis",
    year == 2013 ~ "BLM Start",
    year == 2020 ~ "Geroge Floyd",
    TRUE ~ "None"
  ))

# Plotting the trend
ggplot(hate_crime_trend) +
  aes(x=year, y=total_hate_crimes, color = event) +
  geom_line(color = "black") +
  geom_point(size = 2) +
  scale_color_manual(values = c(
    "9/11" = "red", 
    "Financial Crisis" = "red", 
    "BLM Start" = "red", 
    "COVID-19" = "red", 
    "Geroge Floyd" = "red",
    "None" = "black"
  )) +
  labs(title = "Hate Crimes Over Time",
       subtitle = "Total reported cases 2016 - 2023",
       x = "Year",
       y = "Total Hate Crimes") +
  scale_x_continuous(breaks=seq(1991, 2023, by = 5)) +
  scale_y_continuous(breaks=seq(2500, 13000, by = 2500)) +
  #COVID
  geom_vline(xintercept = (2020 + 2023) / 2, color = "red", size = 20, alpha = 0.4) +
  annotate(geom = "text", x = 2001, y = 10000, label = "911", color = "red", vjust = -0.5, fontface = "bold") + 
  annotate(geom = "text", x = 2008, y = 8000, label = "Financial\nCrisis", color = "red", vjust = -0.5, fontface = "bold") +
  annotate(geom = "text", x = 2013, y = 6500, label = "BLM", color = "red", vjust = 0.5, hjust = -0.1, fontface = "bold") + 
  annotate(geom = "text", x = 2020, y = 10250, label = "George\nFloyd", color = "red", vjust = 0.5, hjust = 1.2, fontface = "bold") +
  annotate(geom = "text", x = 2021.5, y = 2500, label = "COVID", color = "red", hjust = 0.5, vjust = -2, fontface = "bold") +
  # theme_fivethirtyeight() +
  theme_classic() +
  theme(plot.title = element_text(hjust=0.5),
        plot.subtitle = element_text(hjust=0.5),
        legend.position = "none",
        axis.title.x = element_text(margin = margin(t = 10)), 
        axis.title.y = element_text(margin = margin(r = 10)))
```

```{r message=FALSE, warning=FALSE}
# Which factor influence the overall hate crime change

age_USA <- age_dist_trans %>%
  filter(state == "United States") %>%
  group_by(age, year) %>%
  dplyr::summarise(avg_age_dist = round(mean(age_dist), 2), .groups = "drop") %>%
  pivot_wider(names_from = age, values_from = avg_age_dist)

race_USA <- race_dist_trans %>%
  filter(state == "United States") %>%
  group_by(race, year) %>%
  dplyr::summarise(avg_race_dist = round(mean(race_dist), 2), .groups = "drop") %>%
  pivot_wider(names_from = race, values_from = avg_race_dist)

gender_USA <- gender_dist_trans %>%
  filter(state == "United States") %>%
  group_by(gender, year) %>%
  dplyr::summarise(avg_gender_dist = round(mean(gender_dist), 2), .groups = "drop") %>%
  pivot_wider(names_from = gender, values_from = avg_gender_dist)

gdp_USA <- GDP_state_trans %>%
  filter(state == "United States")
  

hate_data_gen_trend <- hate_data %>%
  filter(year > 2015) %>%
  group_by(year) %>%
  dplyr::summarize(total_hate_crimes = n(), .groups = "keep")

hate_data_gen_trend <- plyr::join_all(list(hate_data_gen_trend, age_USA, race_USA, gender_USA, gdp_USA), by=("year"), type="left")


hate_data_gen_trend$Asian[is.na(hate_data_gen_trend$Asian)] <- mean(hate_data_gen_trend$Asian,na.rm = TRUE)
hate_data_gen_trend$Black[is.na(hate_data_gen_trend$Black)] <- mean(hate_data_gen_trend$Black,na.rm = TRUE)
hate_data_gen_trend$Hispanic[is.na(hate_data_gen_trend$Hispanic)] <- mean(hate_data_gen_trend$Hispanic,na.rm = TRUE)
hate_data_gen_trend$White[is.na(hate_data_gen_trend$White)] <- mean(hate_data_gen_trend$White,na.rm = TRUE)
hate_data_gen_trend$Female[is.na(hate_data_gen_trend$Female)] <- mean(hate_data_gen_trend$Female,na.rm = TRUE)
hate_data_gen_trend$Male[is.na(hate_data_gen_trend$Male)] <- mean(hate_data_gen_trend$Male,na.rm = TRUE)
hate_data_gen_trend$"0-18"[is.na(hate_data_gen_trend$"0-18")] <- mean(hate_data_gen_trend$"0-18",na.rm = TRUE)
hate_data_gen_trend$"19-25"[is.na(hate_data_gen_trend$"19-25")] <- mean(hate_data_gen_trend$"19-25",na.rm = TRUE)
hate_data_gen_trend$"26-34"[is.na(hate_data_gen_trend$"26-34")] <- mean(hate_data_gen_trend$"26-34",na.rm = TRUE)
hate_data_gen_trend$"35-54"[is.na(hate_data_gen_trend$"35-54")] <- mean(hate_data_gen_trend$"35-54",na.rm = TRUE)
hate_data_gen_trend$"55-64"[is.na(hate_data_gen_trend$"55-64")] <- mean(hate_data_gen_trend$"55-64",na.rm = TRUE)
hate_data_gen_trend$"65+"[is.na(hate_data_gen_trend$"65+")] <- mean(hate_data_gen_trend$"65+",na.rm = TRUE)

hate_data_gen_trend = subset(hate_data_gen_trend, select = -c(state)) 




# Prepare data for glmnet
x <- as.matrix(hate_data_gen_trend[, -c(1, 2)])  # Exclude total_hate_crimes
y <- hate_data_gen_trend$total_hate_crimes

# Run ridge regression
ridge_model <- glmnet(x, y, alpha = 0)
print(ridge_model)

# Use cross-validation to find the optimal lambda
cv_ridge <- cv.glmnet(x, y, alpha = 0)
plot(cv_ridge)  # Plot the cross-validation results

# Get the best lambda value that minimizes the cross-validation error
best_lambda <- cv_ridge$lambda.min
cat("Best Lambda:", best_lambda, "\n")

# Extract the coefficients at the optimal lambda
ridge_coef <- coef(ridge_model, s = best_lambda)
print(ridge_coef)
```

```{r message=FALSE, warning=FALSE}
#Asian hate crime increase?

asian_hate_crime <- hate_data %>%
  group_by(year, bias_category) %>%
  dplyr::summarize(total_hate_crimes = n(), .groups = "keep")
  


# Plotting the trend
ggplot(asian_hate_crime) +
  aes(x=year, y=total_hate_crimes, color = bias_category) +
  geom_line() +
  labs(title = "Total Crimes over Time",
       subtitle = ":Total reported cases by bias type: 1991-2023",
       color = "Bias Type",
       x = "Year",
       y = "Total Hate Crimes") + 
  scale_x_continuous(breaks=seq(1991, 2023, by = 5)) +
  scale_y_continuous(breaks=seq(0, 6500, by = 1500)) +
  theme_minimal()
```

```{r message=FALSE, warning=FALSE}
#Hate crimes over Time by state
asian_hate_state <- hate_data %>%
  filter(bias_category == "Race/Ethnicity" & year > 2015) %>%
  select(year, state, state_abbrev, bias_category) %>%
  group_by(year, state) %>%
  dplyr::summarize(total_hate_crimes = n(), .groups = "keep")
  
# ggplot(asian_hate_state) +
#   aes(x=year, y = total_hate_crimes, color = state) +
#   geom_line() +
#   geom_vline(xintercept = 2020, linetype = "dashed", color = "red") +
#   labs(title = "Racial/Ethnicity Bias Hate Crimes Over Time",
#        subtitle = "Selected states with significant changes: 2016-2023",
#        x = "Year", y = "Total Hate Crimes") +
#   theme_minimal()
```

```{r message=FALSE, warning=FALSE}
# Function to run ITS for each state
run_its <- function(data){
  lm_model <- lm(total_hate_crimes ~ year + covid, data = data)
  tidy(lm_model)
}

# Add a binary variable for COVID period
asian_hate_state_ITS <- asian_hate_state %>%
  mutate(covid = ifelse(year >= 2020, 1, 0))

its_result <- asian_hate_state_ITS %>%
  group_by(state) %>%
  group_modify(~ run_its(.))

# Filter states with significant results
sig_states_its <- its_result %>%
  filter(term == "covid", p.value < 0.05)
  # %>% select(state, p.value)

print(sig_states_its)


# Graph racial hate crimes over time for selected state
asian_hate_state %>%
filter(state %in% c("Delaware", "District of Columbia" ,"Kansas", "Maine", "Massachusetts", "Minnesota", "Nevada", "Ohio", "Oregon", "Vermont", "Wisconsin", "Wyoming")) %>%
ggplot() +
  aes(x=year, y = total_hate_crimes, color = state) +
  geom_line() +
  geom_vline(xintercept = 2020, linetype = "dashed", color = "red") +
  labs(title = "Racial/Ethnicity Bias Hate Crimes Over Time",
       subtitle = "Selected states with significant changes: 2016-2023",
       x = "Year",
       y = "Total Hate Crimes",
       color = "State") +
  theme_minimal()+
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        plot.title = element_text(hjust=0.5),
        plot.subtitle = element_text(hjust=0.5))
```


```{r message=FALSE, warning=FALSE}
# Identify which social factors were most closely associated with the increase in hate crimes

#Data preparation, merging dataset
iden_state <- c("Delaware", "District of Columbia" ,"Kansas", "Maine", "Massachusetts", "Minnesota", "Nevada", "Ohio", "Oregon", "Vermont", "Wisconsin", "Wyoming")

asian_factor_state <- hate_data %>%
  filter(year > 2015) %>%
  filter(state %in% iden_state) %>%
  group_by(year, state) %>%
  dplyr::summarize(total_hate_crimes = n(), .groups = "keep")

age_sel <- age_dist_trans %>%
  filter(state %in% iden_state) %>%
  group_by(state, age, year) %>%
  dplyr::summarise(avg_age_dist = round(mean(age_dist), 2), .groups = "drop") %>%
  pivot_wider(names_from = age, values_from = avg_age_dist)

race_sel <- race_dist_trans %>%
  filter(state %in% iden_state) %>%
  group_by(state, race, year) %>%
  dplyr::summarise(avg_race_dist = round(mean(race_dist), 2), .groups = "drop") %>%
  pivot_wider(names_from = race, values_from = avg_race_dist)

gender_sel <- gender_dist_trans %>%
  filter(state %in% iden_state) %>%
  group_by(state, gender, year) %>%
  dplyr::summarise(avg_gender_dist = round(mean(gender_dist), 2), .groups = "drop") %>%
  pivot_wider(names_from = gender, values_from = avg_gender_dist)

gdp_sel <- GDP_state_trans %>%
  filter(state %in% iden_state)

density_sel <- pop_density %>%
  filter(state %in% iden_state)

pol_sel <- political_leaning_trans %>%
  filter(state %in% iden_state)

unemp_sel <- unemp_state %>%
  filter(state %in% iden_state)



sel_factor_comp_data <- plyr::join_all(
  list(asian_factor_state, age_sel, race_sel, gender_sel, gdp_sel,
       density_sel, pol_sel, unemp_sel),
  by=c("state","year"),
  type="left")


#adding Wyoming 2018(don't know why it got deleted so i added manually)
new_row <- data.frame(year = as.integer(2018), state = "Wyoming", Asian = 0.00, Black = 0.00, Hispanic = 0.10, White = 0.84, Female = 0.5, Male = 0.5, gdp = 37977.2, density = 6, avg.emp = 4.06)

# Final Dataset for factor comparison by state
sel_factor_comp_data <- bind_rows(sel_factor_comp_data, new_row) %>%
  mutate(
    young = `0-18` + `19-25`,                
    middle_Aged = `26-34` + `35-54`,          
    old = `55-64` + `65+`
  ) %>%
  select(-`0-18`, -`19-25`, -`26-34`, -`35-54`, -`55-64`, -`65+`) %>%
  select(state, state_abbrev, year, total_hate_crimes, Male, Female, young, middle_Aged, old, Asian, Black, Hispanic, White, political, gdp, density, avg.emp) %>%
  group_by(state) %>%
  fill(political, .direction = "downup")
```


```{r message=FALSE, warning=FALSE}
# Panel data regression

panel_data <- pdata.frame(sel_factor_comp_data, index = c("state", "year"))

#Check Multicollinearity
lm_model <- lm(total_hate_crimes ~ Male + young + middle_Aged + old +
                 Asian + Black + Hispanic  + White +
                 gdp + density + avg.emp + political, 
               data = sel_factor_comp_data)

vif(lm_model) #drop old and white

fix_model <- plm(total_hate_crimes ~ Male + young + middle_Aged + 
                  Asian + Black + Hispanic + 
                  gdp + density + avg.emp + political, 
                data = panel_data, model = "within")
summary(fix_model)
```

```{r message=FALSE, warning=FALSE}
# Prediction

# Summarize total hate crimes by year
hate_crime_ts <- hate_data %>%
  group_by(year) %>%
  dplyr::summarize(total_hate_crimes = n(), .groups = "keep") %>%
  arrange(year)

# Convert to time series object
hate_crime_ts_data <- ts(hate_crime_ts$total_hate_crimes, start = 1991, frequency = 1)
plot(hate_crime_ts_data, main = "Before prediction")

# Fit ARIMA model
arima_model <- auto.arima(hate_crime_ts_data)
summary(arima_model)

# Forecast for the next 10 years
forecast_hate_crime <- forecast(arima_model, h = 10)

# Plot the forecast
plot(forecast_hate_crime, main = "Hate Crime Forecast for Next 10 Years",
     ylab = "Total Hate Crimes", xlab = "Year")

```

